"""
------------------------------------------------------------------------------
classify.py — Batch Gaussian Patch Classifier (using Script 1 annotations)

Purpose:
  - Compute global Gaussian patch statistics (mean & covariance) from positive
    and negative rectangles recorded by Script 1 in a shapefile.
  - List all *.tif images in the current working directory.
  - Classify each *.tif in parallel (up to 16 images at once) and write
    ENVI Float32 outputs named "<input_basename>_classification.bin".

Usage:
  python3 classify.py /path/to/annotation_labels.shp

Inputs:
  - sys.argv[1]: Path to the shapefile produced by Script 1, containing fields:
      * CLASS       : "POSITIVE" or "NEGATIVE"
      * SRC_IMAGE   : basename of the source raster (e.g., "image.bin" or "image.tif")
      * COORDS_IMG  : pixel polygon vertices as "c,r;c,r;..." (columns, rows)

Data alignment & assumptions:
  - Labels: CLASS "POSITIVE" → 1, "NEGATIVE" → 0.
  - Rectangle extraction: COORDS_IMG provides pixel-space vertices; bounds are
    derived via min/max of columns (x) and rows (y) → (x0, y0, x1, y1).
  - Patch size: 7×7, with 'reflect' padding; classification uses Mahalanobis
    distance against class mean/covariance.
  - Global stats are computed first from all rectangles across all referenced
    images (images not found are skipped).
  - Outer parallelism: up to 16 concurrent image classifications.
  - Inner parallelism: per-row classification within each image uses all cores.

Outputs:
  - ENVI raster (Float32, 1 band) named "<original_basename>_classification.bin"
    with geotransform and projection copied from the input dataset.
  - In-memory classification is uint8 {0,1} but saved as Float32 for compatibility.

Dependencies:
  - Python 3.x, GDAL (osgeo.gdal, osgeo.ogr), NumPy, joblib

Notes:
  - Only *.tif files in the current directory are classified (regardless of
    which images the training rectangles reference).
  - Progress bars print per-row during classification; large images may take time.
  - Covariance matrices are regularized with 1e-5 * I for stability; pseudo-inverse
    is used if inversion fails.

Algorithmic description generated by copilot AI:
------------------------------------------------------------------------------
Classifier Technical Details — Gaussian Patch Classifier (Mahalanobis-based)

Model:
  - Binary classifier with two class-conditional multivariate normal models:
      * Class 0 (NEGATIVE): N(μ0, Σ0)
      * Class 1 (POSITIVE): N(μ1, Σ1)
  - Decision rule per pixel uses Mahalanobis distance on flattened patch vectors:
      δk(x) = (x - μk)^T Σk^{-1} (x - μk),  k ∈ {0,1}
    Predict class = argmin_k δk(x). (Equal priors and no log-det term assumed.)
  - Patches are extracted as fixed-size windows (7×7) centered at each pixel;
    per-pixel classification uses the flattened patch vector across all bands.

Feature construction:
  - Input raster is shape (H, W, B). For patch size P (default 7), each feature
    vector is length D = P×P×B.
  - Training samples are collected from rectangles in pixel coordinates (x0,y0,x1,y1)
    for each labeled class. Every pixel within each rectangle contributes one patch.
  - 'reflect' padding is used so patches near borders have valid neighborhoods.

Parameter estimation:
  - For each class k, concatenate all class-specific patch vectors into matrix Xk
    of shape (Nk, D), then compute:
      μk = mean(Xk, axis=0)
      Σk = cov(Xk, rowvar=False) + λ I
    where λ = 1e-5 provides Tikhonov-style regularization to stabilize inversion.
  - If Σk is singular or ill-conditioned, pseudo-inverse is used (pinv),
    otherwise the ordinary inverse is computed.

Classification runtime:
  - Inner parallelism: rows are processed in parallel using joblib (loky),
    partitioning by scanline; each thread computes δ0 and δ1 for all pixels
    in its assigned row.
  - Outer parallelism: images are classified in parallel with a cap (e.g., 16
    concurrent jobs) to avoid oversubscription and excessive memory pressure.

Numerical stability & scaling:
  - Regularization λI ensures Σk is positive definite (or close to), improving
    numerical stability of inversion and Mahalanobis distance evaluation.
  - If training sample size Nk < D (high-dimensional features with limited
    samples), Σk can be poorly estimated; consider:
      * Larger rectangles (more samples) or smaller patches (reduce D).
      * Band selection or PCA to reduce feature dimensionality.
      * Shared covariance (LDA-like) as an alternative (not implemented here).

Complexity:
  - Training: O(N0·D^2 + N1·D^2) to estimate covariances (dominant term),
    plus inversion cost O(D^3) for each Σk (or pinv with similar cubic scaling).
  - Inference per image: O(H·W·D) arithmetic with two quadratic forms per pixel.
  - Memory:
      * Training stores samples transiently; careful with large rectangles and
        many bands as D grows quickly (P×P×B).
      * Classification buffers include padded image and output masks.

Class imbalance:
  - If classes are imbalanced, μk and Σk may be biased toward majority class.
    Techniques to mitigate (not implemented here): downsample majority patches,
    upsample minority patches, or apply class priors in decision rule by adding
    log|Σk| and log prior terms to δk(x).

Assumptions:
  - Stationarity: The same Gaussian patch statistics generalize across images
    (global model). This is appropriate when acquisition conditions and targets
    are similar; otherwise per-image or domain-adaptive statistics may be preferable.
  - Equal priors & equal misclassification costs; can be adjusted by thresholds
    or explicit priors if needed.

I/O & outputs:
  - Output classification is written per image as ENVI Float32 raster named
    "<input_basename>_classification.bin", with geotransform and projection copied
    from the source dataset. In-memory mask uses uint8 {0,1} but is saved as float32.

Parallel execution notes:
  - Inner joblib over rows uses n_jobs=-1 (all available cores) for per-image
    inference. Outer joblib over images is capped (e.g., 16) to balance throughput
    and resource usage. Adjust these caps based on CPU count, RAM, and image size.

Patch size choice:
  - P=7 offers a tradeoff between local context and dimensionality; larger patches
    may capture more texture/context but exacerbate covariance estimation challenges.
    Smaller patches reduce D and improve covariance reliability but may miss context.

Failure handling:
  - If either class lacks samples, its μk, Σk are None, and δk(x) becomes ∞.
    Classification defaults to the other class; if both are None, the process aborts.
------------------------------------------------------------------------------
"""

#!/usr/bin/env python3

import sys, os
from osgeo import gdal, ogr
import numpy as np
from joblib import Parallel, delayed

# ---------- classification (from Script 2) ----------
def print_progress_bar(i, total, prefix='', suffix='', length=40, fill='█'):
    pct = f"{100 * (i / float(total)):.1f}"
    filled = int(length * i // total)
    bar = fill * filled + '-' * (length - filled)
    print(f'\r{prefix} |{bar}| {pct}% {suffix}', end='\r')
    if i == total: print()

def classify_pixel(padded, y, x, patch, mean_covs, inv_cov):
    v = padded[y:y+patch, x:x+patch, :].reshape(-1)
    s0 = s1 = np.inf
    if mean_covs[0][0] is not None and inv_cov[0] is not None:
        d = v - mean_covs[0][0]; s0 = d @ inv_cov[0] @ d
    if mean_covs[1][0] is not None and inv_cov[1] is not None:
        d = v - mean_covs[1][0]; s1 = d @ inv_cov[1] @ d
    return 1 if s1 < s0 else 0

def classify_by_gaussian_parallel(image, mean_covs, patch_size=7):
    h, w, _ = image.shape
    pad = patch_size // 2
    padded = np.pad(image, ((pad, pad), (pad, pad), (0, 0)), mode='reflect')
    out = np.zeros((h, w), dtype=np.uint8)
    inv_cov = {}
    for lbl in (0, 1):
        mean, cov = mean_covs[lbl]
        if mean is None or cov is None:
            inv_cov[lbl] = None
        else:
            try: inv_cov[lbl] = np.linalg.inv(cov)
            except np.linalg.LinAlgError: inv_cov[lbl] = np.linalg.pinv(cov)
    def classify_row(y):
        r = np.zeros(w, dtype=np.uint8)
        for x in range(w): r[x] = classify_pixel(padded, y, x, patch_size, mean_covs, inv_cov)
        return r
    rows = Parallel(n_jobs=-1, backend="loky")(delayed(classify_row)(y) for y in range(h))
    for y, r in enumerate(rows, 1):
        out[y-1, :] = r
        print_progress_bar(y, h, prefix='Progress:', suffix='Done')
    return out

def compute_patch_mean_cov(image, rectangles, labels, patch_size=7):
    pad = patch_size // 2
    padded = np.pad(image, ((pad, pad), (pad, pad), (0, 0)), mode='reflect')
    h, w, _ = image.shape
    S = {0: [], 1: []}
    for (x0, y0, x1, y1), lbl in zip(rectangles, labels):
        x0 = max(0, int(x0)); y0 = max(0, int(y0))
        x1 = min(w, int(x1)); y1 = min(h, int(y1))
        if x1 <= x0 or y1 <= y0: continue
        for y in range(y0, y1):
            for x in range(x0, x1):
                S[lbl].append(padded[y:y+patch_size, x:x+patch_size, :].reshape(-1))
    out = {}
    for lbl in (0, 1):
        if S[lbl]:
            D = np.vstack(S[lbl])
            mean = D.mean(axis=0)
            cov = np.cov(D, rowvar=False) + np.eye(D.shape[1]) * 1e-5
            out[lbl] = (mean, cov)
        else:
            out[lbl] = (None, None)
    return out

def save_envi_classification(dataset, classification):
    driver = gdal.GetDriverByName('ENVI')
    h, w = classification.shape
    in_path = dataset.GetDescription()
    base, _ = os.path.splitext(in_path)
    out_file = f"{base}_classification.bin"
    ds_out = driver.Create(out_file, w, h, 1, gdal.GDT_Float32)
    if ds_out is None:
        print(f"Error creating {out_file}")
        return None
    gt = dataset.GetGeoTransform(); pr = dataset.GetProjection()
    if gt: ds_out.SetGeoTransform(gt)
    if pr: ds_out.SetProjection(pr)
    b = ds_out.GetRasterBand(1)
    b.WriteArray(classification.astype(np.float32))
    b.FlushCache(); ds_out.FlushCache()
    print(f"Saved: {out_file}")
    return out_file

# ---------- Script 1 shapefile parsing ----------
def parse_coords_img_to_rect(coords_img_str):
    if not coords_img_str or str(coords_img_str).upper() == "NO_RASTER": return None
    try:
        xs, ys = [], []
        for tok in str(coords_img_str).split(';'):
            tok = tok.strip()
            if not tok: continue
            c_str, r_str = tok.split(',')
            xs.append(int(round(float(c_str))))
            ys.append(int(round(float(r_str))))
        if not xs or not ys: return None
        x0, x1 = min(xs), max(xs); y0, y1 = min(ys), max(ys)
        if x1 == x0 or y1 == y0: return None
        return (x0, y0, x1, y1)
    except Exception:
        return None

def read_training_from_shapefile(shp_path):
    ds = ogr.Open(shp_path, 0)
    if ds is None: raise RuntimeError(f"Failed to open shapefile: {shp_path}")
    lyr = ds.GetLayer(0)
    out = {}
    for f in lyr:
        cls = f.GetField("CLASS")
        src = f.GetField("SRC_IMAGE")
        coords = f.GetField("COORDS_IMG")
        if not src or not isinstance(cls, str): continue
        cu = cls.strip().upper()
        lbl = 1 if cu == "POSITIVE" else 0 if cu == "NEGATIVE" else None
        if lbl is None: continue
        rect = parse_coords_img_to_rect(coords)
        if rect is None: continue
        out.setdefault(src, {'rectangles': [], 'labels': []})
        out[src]['rectangles'].append(rect)
        out[src]['labels'].append(lbl)
    return out

# ---------- image I/O ----------
def locate_image_by_basename(basename, dirs):
    for d in dirs:
        p = os.path.join(d, basename)
        if os.path.isfile(p): return p
    for d in dirs:
        for root, _, files in os.walk(d):
            if basename in files: return os.path.join(root, basename)
    return None

def load_image_stack(path):
    ds = gdal.Open(path, gdal.GA_ReadOnly)
    if ds is None: raise RuntimeError(f"Failed to open image: {path}")
    w, h, b = ds.RasterXSize, ds.RasterYSize, ds.RasterCount
    data = np.stack([ds.GetRasterBand(i+1).ReadAsArray().astype(np.float32) for i in range(b)], axis=-1)
    assert data.shape == (h, w, b)
    return data, ds

# ---------- main ----------
def main():
    if len(sys.argv) < 2:
        print("Usage: python3 classify.py /path/to/annotation_labels.shp"); sys.exit(1)
    shp = sys.argv[1]
    shp_dir = os.path.dirname(os.path.abspath(shp)); cwd = os.getcwd()
    training = read_training_from_shapefile(shp)
    if not training:
        print("No training rectangles found."); sys.exit(1)

    # GLOBAL stats from all training rectangles (across referenced images)
    S0, S1 = [], []
    for src, d in training.items():
        img_path = locate_image_by_basename(src, [shp_dir, cwd])
        if img_path is None: continue
        try:
            img, _ds = load_image_stack(img_path)
        except Exception:
            continue
        pad = 7 // 2
        padded = np.pad(img, ((pad, pad), (pad, pad), (0, 0)), mode='reflect')
        h, w, _ = img.shape
        rects, labels = d['rectangles'], d['labels']
        for (x0, y0, x1, y1), lbl in zip(rects, labels):
            x0 = max(0, int(x0)); y0 = max(0, int(y0))
            x1 = min(w, int(x1)); y1 = min(h, int(y1))
            if x1 <= x0 or y1 <= y0: continue
            tgt = S1 if lbl == 1 else S0
            for y in range(y0, y1):
                for x in range(x0, x1):
                    tgt.append(padded[y:y+7, x:x+7, :].reshape(-1))
    mean_covs = {0:(None,None), 1:(None,None)}
    for lbl, S in ((0, S0), (1, S1)):
        if S:
            D = np.vstack(S)
            mean = D.mean(axis=0)
            cov = np.cov(D, rowvar=False) + np.eye(D.shape[1]) * 1e-5
            mean_covs[lbl] = (mean, cov)
    if mean_covs[0][0] is None and mean_covs[1][0] is None:
        print("No valid samples across images."); sys.exit(1)

    # List all *.tif in current directory (regardless of reference association)
    tif_files = sorted([f for f in os.listdir(cwd) if f.lower().endswith('.tif')])
    print(f"*.tif images in current directory ({len(tif_files)}): {tif_files}")
    if not tif_files:
        print("No .tif images found."); sys.exit(0)

    # Parallel classification across *.tif (limit to 16 concurrent jobs)
    def classify_one_tif(fname):
        path = os.path.join(cwd, fname)
        try:
            img, ds = load_image_stack(path)
        except Exception as e:
            return (fname, f"open_failed: {e}")
        cls = classify_by_gaussian_parallel(img, mean_covs, patch_size=7)
        out = save_envi_classification(ds, cls)
        return (fname, out if out else "save_failed")

    results = Parallel(n_jobs=16, backend="loky")(delayed(classify_one_tif)(f) for f in tif_files)
    for fname, status in results:
        print(f"{fname} -> {status}")

if __name__ == "__main__":
    main()
